{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot Training Notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2D97AlMM5PaF",
        "outputId": "f9025100-0acb-41f8-a552-7c7939ea6645"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Jul  1 08:47:08 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   59C    P0    30W /  70W |    432MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lbc1Sdoj5ihH",
        "outputId": "87508c83-3553-44bf-b151-3c40f8b8dcd0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/My Community session/Projects')\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zcCdMZLY5j5s",
        "outputId": "949e65b5-b671-4900-868a-3592f9705cbc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/My Community session/Projects'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/drive/MyDrive/My Community session/data/job_intents.json\""
      ],
      "metadata": {
        "id": "qIgd4nsS5uMk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import tensorflow as tf\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvtxL5oZ51SB",
        "outputId": "ef816a3a-01b2-4f8e-bbda-c7e47d9f2cec"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Preprocessing"
      ],
      "metadata": {
        "id": "Y6XjTA0E55k8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words=[] #all unique words\n",
        "classes = []  #all classed\n",
        "documents = [] #all input with label\n",
        "ignore_words = ['?', '!']\n",
        "\n",
        "data_file = open(data_path, encoding='utf-8').read()\n",
        "intents = json.loads(data_file)"
      ],
      "metadata": {
        "id": "h44Q5rr053Ib"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for intent in intents['intents']:\n",
        "    for pattern in intent['patterns']:\n",
        "\n",
        "        w = nltk.word_tokenize(pattern)\n",
        "        words.extend(w)\n",
        "\n",
        "        documents.append((w, intent['tag']))\n",
        "\n",
        "\n",
        "        if intent['tag'] not in classes:\n",
        "            classes.append(intent['tag'])"
      ],
      "metadata": {
        "id": "KY3Aufeo58ri"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "SKPpfUVX6Dtx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm_words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]"
      ],
      "metadata": {
        "id": "rBfc8cGk6HJa"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lm_words = sorted(list(set(lm_words)))\n",
        "lm_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whTOZMvY6Nj0",
        "outputId": "bea43635-01f5-435a-ee8a-a1991881a9e4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"'s\",\n",
              " ',',\n",
              " 'about',\n",
              " 'africa',\n",
              " 'anyone',\n",
              " 'are',\n",
              " 'awesome',\n",
              " 'bye',\n",
              " 'can',\n",
              " 'day',\n",
              " 'do',\n",
              " 'ekse',\n",
              " 'fact',\n",
              " 'for',\n",
              " 'give',\n",
              " 'good',\n",
              " 'goodbye',\n",
              " 'hello',\n",
              " 'help',\n",
              " 'helpful',\n",
              " 'helping',\n",
              " 'hey',\n",
              " 'hi',\n",
              " 'hola',\n",
              " 'how',\n",
              " 'interesting',\n",
              " 'is',\n",
              " 'know',\n",
              " 'later',\n",
              " 'me',\n",
              " 'more',\n",
              " 'name',\n",
              " 'ok',\n",
              " 'purpose',\n",
              " 'sa',\n",
              " 'see',\n",
              " 'some',\n",
              " 'something',\n",
              " 'south',\n",
              " 'tell',\n",
              " 'thank',\n",
              " 'thanks',\n",
              " 'that',\n",
              " 'there',\n",
              " 'ungubani',\n",
              " 'what',\n",
              " 'whats',\n",
              " 'who',\n",
              " 'you',\n",
              " 'your',\n",
              " 'yourself']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = sorted(list(set(classes)))\n",
        "\n",
        "print (len(documents), \"documents\")\n",
        "print (len(classes), \"classes\", classes)\n",
        "print (len(lm_words), \"unique lemmatized words\", lm_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjgLT0EK6PBx",
        "outputId": "8b73c723-d712-44f2-8eb0-85e9d13f7c83"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53 documents\n",
            "7 classes ['goodbye', 'greeting', 'name', 'options', 'south_africa_facts', 'south_africa_info', 'thanks']\n",
            "51 unique lemmatized words [\"'s\", ',', 'about', 'africa', 'anyone', 'are', 'awesome', 'bye', 'can', 'day', 'do', 'ekse', 'fact', 'for', 'give', 'good', 'goodbye', 'hello', 'help', 'helpful', 'helping', 'hey', 'hi', 'hola', 'how', 'interesting', 'is', 'know', 'later', 'me', 'more', 'name', 'ok', 'purpose', 'sa', 'see', 'some', 'something', 'south', 'tell', 'thank', 'thanks', 'that', 'there', 'ungubani', 'what', 'whats', 'who', 'you', 'your', 'yourself']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(lm_words,open('words.pkl','wb'))\n",
        "pickle.dump(classes,open('classes.pkl','wb'))"
      ],
      "metadata": {
        "id": "SNxhYOct6TfZ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering / Text representation"
      ],
      "metadata": {
        "id": "KcEoqBkY6cyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initializing training data\n",
        "training = []\n",
        "output_empty = [0] * len(classes)"
      ],
      "metadata": {
        "id": "jx3_8Amu6Z3A"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in documents:\n",
        "\n",
        "    bag = []\n",
        "\n",
        "    pattern_words = doc[0]\n",
        "    pattern_words = [lemmatizer.lemmatize(word.lower()) for word in pattern_words]\n",
        "\n",
        "    for w in lm_words:\n",
        "        bag.append(1) if w in pattern_words else bag.append(0)\n",
        "\n",
        "\n",
        "    output_row = list(output_empty)\n",
        "    output_row[classes.index(doc[1])] = 1\n",
        "    training.append([bag, output_row])"
      ],
      "metadata": {
        "id": "JA_SBoXC6h84"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.shuffle(training)\n",
        "training = np.array(training)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_AVUlTD6lu_",
        "outputId": "becc5e89-e030-4a32-9ec6-6bf982f080b1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82hCGMVT6oO7",
        "outputId": "4e894608-8338-44fe-89cd-8f768ad93b97"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(53, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create train and test lists. X - patterns, Y - intents\n",
        "train_x = list(training[:,0])\n",
        "train_y = list(training[:,1])\n",
        "\n",
        "VALIDATION_SET = (train_x, train_y)"
      ],
      "metadata": {
        "id": "Rl9cQz_66qLx"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modeling & Evaluation"
      ],
      "metadata": {
        "id": "NgquuWGo7D53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model - 3 layers. First layer 128 neurons, second layer 64 neurons and 3rd output layer contains number of neurons\n",
        "# equal to number of intents to predict output intent with softmax\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(len(train_x[0]),), activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(train_y[0]), activation='softmax'))"
      ],
      "metadata": {
        "id": "IOvIfvTA7B0R"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model. Stochastic gradient descent with Nesterov accelerated gradient gives good results for this model\n",
        "sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "7VPjOCf77Gjh"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting and saving the model\n",
        "history = model.fit(np.array(train_x), np.array(train_y), epochs=250, validation_data = VALIDATION_SET, batch_size=5, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJLW4NW07IPV",
        "outputId": "81b8abc2-91b6-4056-ead0-2a8f18a5276b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "11/11 [==============================] - 1s 24ms/step - loss: 1.9881 - accuracy: 0.0755 - val_loss: 1.8693 - val_accuracy: 0.2453\n",
            "Epoch 2/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1.8754 - accuracy: 0.2075 - val_loss: 1.7437 - val_accuracy: 0.2830\n",
            "Epoch 3/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.7851 - accuracy: 0.3208 - val_loss: 1.6135 - val_accuracy: 0.3019\n",
            "Epoch 4/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.6613 - accuracy: 0.3962 - val_loss: 1.4816 - val_accuracy: 0.4340\n",
            "Epoch 5/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.5780 - accuracy: 0.4151 - val_loss: 1.3581 - val_accuracy: 0.6038\n",
            "Epoch 6/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.4498 - accuracy: 0.5094 - val_loss: 1.2308 - val_accuracy: 0.6226\n",
            "Epoch 7/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.3111 - accuracy: 0.5849 - val_loss: 1.1140 - val_accuracy: 0.7358\n",
            "Epoch 8/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 1.2165 - accuracy: 0.6415 - val_loss: 0.9891 - val_accuracy: 0.7925\n",
            "Epoch 9/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 1.0788 - accuracy: 0.6415 - val_loss: 0.8842 - val_accuracy: 0.7925\n",
            "Epoch 10/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 1.0160 - accuracy: 0.6981 - val_loss: 0.7953 - val_accuracy: 0.8302\n",
            "Epoch 11/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.9048 - accuracy: 0.6981 - val_loss: 0.7125 - val_accuracy: 0.8302\n",
            "Epoch 12/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8726 - accuracy: 0.7736 - val_loss: 0.6344 - val_accuracy: 0.8679\n",
            "Epoch 13/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.8212 - accuracy: 0.7547 - val_loss: 0.5696 - val_accuracy: 0.9245\n",
            "Epoch 14/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.8077 - accuracy: 0.6792 - val_loss: 0.5075 - val_accuracy: 0.9434\n",
            "Epoch 15/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6534 - accuracy: 0.8302 - val_loss: 0.4427 - val_accuracy: 0.9434\n",
            "Epoch 16/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.7127 - accuracy: 0.7925 - val_loss: 0.3921 - val_accuracy: 0.9434\n",
            "Epoch 17/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6037 - accuracy: 0.8113 - val_loss: 0.3432 - val_accuracy: 0.9811\n",
            "Epoch 18/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.5775 - accuracy: 0.7736 - val_loss: 0.3011 - val_accuracy: 0.9811\n",
            "Epoch 19/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.6327 - accuracy: 0.8113 - val_loss: 0.2638 - val_accuracy: 0.9811\n",
            "Epoch 20/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.5531 - accuracy: 0.8491 - val_loss: 0.2358 - val_accuracy: 0.9811\n",
            "Epoch 21/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3336 - accuracy: 0.9434 - val_loss: 0.2044 - val_accuracy: 1.0000\n",
            "Epoch 22/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3888 - accuracy: 0.8868 - val_loss: 0.1749 - val_accuracy: 1.0000\n",
            "Epoch 23/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3164 - accuracy: 0.9057 - val_loss: 0.1599 - val_accuracy: 1.0000\n",
            "Epoch 24/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.4317 - accuracy: 0.8868 - val_loss: 0.1327 - val_accuracy: 1.0000\n",
            "Epoch 25/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3450 - accuracy: 0.9057 - val_loss: 0.1249 - val_accuracy: 1.0000\n",
            "Epoch 26/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3052 - accuracy: 0.8868 - val_loss: 0.1016 - val_accuracy: 1.0000\n",
            "Epoch 27/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.4180 - accuracy: 0.8679 - val_loss: 0.0859 - val_accuracy: 1.0000\n",
            "Epoch 28/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3091 - accuracy: 0.8868 - val_loss: 0.0802 - val_accuracy: 1.0000\n",
            "Epoch 29/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.2617 - accuracy: 0.9245 - val_loss: 0.0741 - val_accuracy: 1.0000\n",
            "Epoch 30/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.2759 - accuracy: 0.9434 - val_loss: 0.0701 - val_accuracy: 1.0000\n",
            "Epoch 31/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.2614 - accuracy: 0.9057 - val_loss: 0.0648 - val_accuracy: 1.0000\n",
            "Epoch 32/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1739 - accuracy: 0.9811 - val_loss: 0.0576 - val_accuracy: 1.0000\n",
            "Epoch 33/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.3535 - accuracy: 0.8868 - val_loss: 0.0454 - val_accuracy: 1.0000\n",
            "Epoch 34/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.2075 - accuracy: 0.9434 - val_loss: 0.0421 - val_accuracy: 1.0000\n",
            "Epoch 35/250\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.1777 - accuracy: 0.9434 - val_loss: 0.0361 - val_accuracy: 1.0000\n",
            "Epoch 36/250\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.1707 - accuracy: 0.9811 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
            "Epoch 37/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.2380 - accuracy: 0.9245 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
            "Epoch 38/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1241 - accuracy: 0.9811 - val_loss: 0.0279 - val_accuracy: 1.0000\n",
            "Epoch 39/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1126 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
            "Epoch 40/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1180 - accuracy: 0.9623 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
            "Epoch 41/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0989 - accuracy: 1.0000 - val_loss: 0.0201 - val_accuracy: 1.0000\n",
            "Epoch 42/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1010 - accuracy: 0.9811 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
            "Epoch 43/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1989 - accuracy: 0.9434 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
            "Epoch 44/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0958 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 1.0000\n",
            "Epoch 45/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0585 - accuracy: 1.0000 - val_loss: 0.0114 - val_accuracy: 1.0000\n",
            "Epoch 46/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1442 - accuracy: 0.9623 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
            "Epoch 47/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1163 - accuracy: 0.9623 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
            "Epoch 48/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.2788 - accuracy: 0.9245 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
            "Epoch 49/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1380 - accuracy: 0.9811 - val_loss: 0.0110 - val_accuracy: 1.0000\n",
            "Epoch 50/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1094 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
            "Epoch 51/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0550 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 1.0000\n",
            "Epoch 52/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1231 - accuracy: 0.9811 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
            "Epoch 53/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0866 - accuracy: 0.9811 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 54/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0568 - accuracy: 0.9811 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
            "Epoch 55/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0991 - accuracy: 0.9811 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
            "Epoch 56/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0796 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 57/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0735 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
            "Epoch 58/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0394 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 59/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0510 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 60/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0675 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 61/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0921 - accuracy: 0.9811 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 62/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0834 - accuracy: 0.9623 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 63/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0647 - accuracy: 1.0000 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 64/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0705 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 65/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 66/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 67/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1177 - accuracy: 0.9623 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 68/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0382 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 69/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1477 - accuracy: 0.9623 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 70/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0853 - accuracy: 0.9811 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 71/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0884 - accuracy: 0.9811 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 72/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0528 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 73/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0594 - accuracy: 0.9811 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 74/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1213 - accuracy: 0.9623 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 75/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0545 - accuracy: 0.9811 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 76/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0492 - accuracy: 1.0000 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 77/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0456 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 78/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.1501 - accuracy: 0.9623 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 79/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0339 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 80/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0874 - accuracy: 0.9623 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 81/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 82/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0354 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 83/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0445 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 84/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0453 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 85/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0397 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 86/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0435 - accuracy: 0.9811 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 87/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0428 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 88/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 89/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0535 - accuracy: 0.9811 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 90/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0408 - accuracy: 1.0000 - val_loss: 9.8762e-04 - val_accuracy: 1.0000\n",
            "Epoch 91/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 8.8528e-04 - val_accuracy: 1.0000\n",
            "Epoch 92/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0781 - accuracy: 0.9811 - val_loss: 8.5271e-04 - val_accuracy: 1.0000\n",
            "Epoch 93/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0460 - accuracy: 0.9811 - val_loss: 8.4925e-04 - val_accuracy: 1.0000\n",
            "Epoch 94/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0430 - accuracy: 1.0000 - val_loss: 8.5152e-04 - val_accuracy: 1.0000\n",
            "Epoch 95/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0433 - accuracy: 0.9811 - val_loss: 8.5815e-04 - val_accuracy: 1.0000\n",
            "Epoch 96/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0514 - accuracy: 0.9811 - val_loss: 8.7387e-04 - val_accuracy: 1.0000\n",
            "Epoch 97/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 8.5399e-04 - val_accuracy: 1.0000\n",
            "Epoch 98/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 8.1657e-04 - val_accuracy: 1.0000\n",
            "Epoch 99/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0371 - accuracy: 1.0000 - val_loss: 7.9590e-04 - val_accuracy: 1.0000\n",
            "Epoch 100/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0474 - accuracy: 1.0000 - val_loss: 7.4240e-04 - val_accuracy: 1.0000\n",
            "Epoch 101/250\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0680 - accuracy: 0.9811 - val_loss: 7.7212e-04 - val_accuracy: 1.0000\n",
            "Epoch 102/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0358 - accuracy: 1.0000 - val_loss: 7.2759e-04 - val_accuracy: 1.0000\n",
            "Epoch 103/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0244 - accuracy: 0.9811 - val_loss: 6.7581e-04 - val_accuracy: 1.0000\n",
            "Epoch 104/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 6.4205e-04 - val_accuracy: 1.0000\n",
            "Epoch 105/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0201 - accuracy: 1.0000 - val_loss: 6.0808e-04 - val_accuracy: 1.0000\n",
            "Epoch 106/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0394 - accuracy: 0.9811 - val_loss: 5.7044e-04 - val_accuracy: 1.0000\n",
            "Epoch 107/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0257 - accuracy: 1.0000 - val_loss: 5.3431e-04 - val_accuracy: 1.0000\n",
            "Epoch 108/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0506 - accuracy: 0.9811 - val_loss: 5.2917e-04 - val_accuracy: 1.0000\n",
            "Epoch 109/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 5.2376e-04 - val_accuracy: 1.0000\n",
            "Epoch 110/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0379 - accuracy: 0.9811 - val_loss: 4.6284e-04 - val_accuracy: 1.0000\n",
            "Epoch 111/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0370 - accuracy: 0.9811 - val_loss: 4.6242e-04 - val_accuracy: 1.0000\n",
            "Epoch 112/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 4.9350e-04 - val_accuracy: 1.0000\n",
            "Epoch 113/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 4.9953e-04 - val_accuracy: 1.0000\n",
            "Epoch 114/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0335 - accuracy: 1.0000 - val_loss: 5.4771e-04 - val_accuracy: 1.0000\n",
            "Epoch 115/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0740 - accuracy: 0.9811 - val_loss: 4.5320e-04 - val_accuracy: 1.0000\n",
            "Epoch 116/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 4.9791e-04 - val_accuracy: 1.0000\n",
            "Epoch 117/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0482 - accuracy: 0.9811 - val_loss: 4.6263e-04 - val_accuracy: 1.0000\n",
            "Epoch 118/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 4.6366e-04 - val_accuracy: 1.0000\n",
            "Epoch 119/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 4.2173e-04 - val_accuracy: 1.0000\n",
            "Epoch 120/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 3.9422e-04 - val_accuracy: 1.0000\n",
            "Epoch 121/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 3.8043e-04 - val_accuracy: 1.0000\n",
            "Epoch 122/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 3.5633e-04 - val_accuracy: 1.0000\n",
            "Epoch 123/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0944 - accuracy: 0.9623 - val_loss: 4.6529e-04 - val_accuracy: 1.0000\n",
            "Epoch 124/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 5.0469e-04 - val_accuracy: 1.0000\n",
            "Epoch 125/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0229 - accuracy: 1.0000 - val_loss: 4.7725e-04 - val_accuracy: 1.0000\n",
            "Epoch 126/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0582 - accuracy: 0.9811 - val_loss: 3.9668e-04 - val_accuracy: 1.0000\n",
            "Epoch 127/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 3.6363e-04 - val_accuracy: 1.0000\n",
            "Epoch 128/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0322 - accuracy: 1.0000 - val_loss: 3.7197e-04 - val_accuracy: 1.0000\n",
            "Epoch 129/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0776 - accuracy: 0.9811 - val_loss: 4.0135e-04 - val_accuracy: 1.0000\n",
            "Epoch 130/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 4.6007e-04 - val_accuracy: 1.0000\n",
            "Epoch 131/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0105 - accuracy: 1.0000 - val_loss: 4.5619e-04 - val_accuracy: 1.0000\n",
            "Epoch 132/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 4.3556e-04 - val_accuracy: 1.0000\n",
            "Epoch 133/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 4.1844e-04 - val_accuracy: 1.0000\n",
            "Epoch 134/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 4.2041e-04 - val_accuracy: 1.0000\n",
            "Epoch 135/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0415 - accuracy: 1.0000 - val_loss: 3.4176e-04 - val_accuracy: 1.0000\n",
            "Epoch 136/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0411 - accuracy: 0.9811 - val_loss: 3.0035e-04 - val_accuracy: 1.0000\n",
            "Epoch 137/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0228 - accuracy: 1.0000 - val_loss: 2.8740e-04 - val_accuracy: 1.0000\n",
            "Epoch 138/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0532 - accuracy: 0.9811 - val_loss: 2.6175e-04 - val_accuracy: 1.0000\n",
            "Epoch 139/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 2.3987e-04 - val_accuracy: 1.0000\n",
            "Epoch 140/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0735 - accuracy: 0.9811 - val_loss: 2.3310e-04 - val_accuracy: 1.0000\n",
            "Epoch 141/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 2.2989e-04 - val_accuracy: 1.0000\n",
            "Epoch 142/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0329 - accuracy: 0.9811 - val_loss: 2.2939e-04 - val_accuracy: 1.0000\n",
            "Epoch 143/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0499 - accuracy: 0.9811 - val_loss: 2.6415e-04 - val_accuracy: 1.0000\n",
            "Epoch 144/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.9326e-04 - val_accuracy: 1.0000\n",
            "Epoch 145/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.1201 - accuracy: 0.9623 - val_loss: 3.0919e-04 - val_accuracy: 1.0000\n",
            "Epoch 146/250\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0319 - accuracy: 1.0000 - val_loss: 3.4283e-04 - val_accuracy: 1.0000\n",
            "Epoch 147/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 3.4494e-04 - val_accuracy: 1.0000\n",
            "Epoch 148/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 3.2755e-04 - val_accuracy: 1.0000\n",
            "Epoch 149/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 3.0862e-04 - val_accuracy: 1.0000\n",
            "Epoch 150/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 2.8079e-04 - val_accuracy: 1.0000\n",
            "Epoch 151/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 2.5674e-04 - val_accuracy: 1.0000\n",
            "Epoch 152/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0234 - accuracy: 1.0000 - val_loss: 2.3619e-04 - val_accuracy: 1.0000\n",
            "Epoch 153/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 2.2853e-04 - val_accuracy: 1.0000\n",
            "Epoch 154/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0345 - accuracy: 1.0000 - val_loss: 2.2978e-04 - val_accuracy: 1.0000\n",
            "Epoch 155/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.3337e-04 - val_accuracy: 1.0000\n",
            "Epoch 156/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.2062e-04 - val_accuracy: 1.0000\n",
            "Epoch 157/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 2.0588e-04 - val_accuracy: 1.0000\n",
            "Epoch 158/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.9420e-04 - val_accuracy: 1.0000\n",
            "Epoch 159/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.8439e-04 - val_accuracy: 1.0000\n",
            "Epoch 160/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.7642e-04 - val_accuracy: 1.0000\n",
            "Epoch 161/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.6943e-04 - val_accuracy: 1.0000\n",
            "Epoch 162/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 1.6196e-04 - val_accuracy: 1.0000\n",
            "Epoch 163/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0236 - accuracy: 1.0000 - val_loss: 1.5507e-04 - val_accuracy: 1.0000\n",
            "Epoch 164/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.4551e-04 - val_accuracy: 1.0000\n",
            "Epoch 165/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0741 - accuracy: 0.9811 - val_loss: 1.4018e-04 - val_accuracy: 1.0000\n",
            "Epoch 166/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0296 - accuracy: 1.0000 - val_loss: 1.3881e-04 - val_accuracy: 1.0000\n",
            "Epoch 167/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 1.3528e-04 - val_accuracy: 1.0000\n",
            "Epoch 168/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.2472e-04 - val_accuracy: 1.0000\n",
            "Epoch 169/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.2033e-04 - val_accuracy: 1.0000\n",
            "Epoch 170/250\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.1406e-04 - val_accuracy: 1.0000\n",
            "Epoch 171/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.0919e-04 - val_accuracy: 1.0000\n",
            "Epoch 172/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.0914e-04 - val_accuracy: 1.0000\n",
            "Epoch 173/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0576 - accuracy: 0.9811 - val_loss: 1.1166e-04 - val_accuracy: 1.0000\n",
            "Epoch 174/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.1042e-04 - val_accuracy: 1.0000\n",
            "Epoch 175/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.0361e-04 - val_accuracy: 1.0000\n",
            "Epoch 176/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 9.9087e-05 - val_accuracy: 1.0000\n",
            "Epoch 177/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 9.5565e-05 - val_accuracy: 1.0000\n",
            "Epoch 178/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 9.2624e-05 - val_accuracy: 1.0000\n",
            "Epoch 179/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 8.9832e-05 - val_accuracy: 1.0000\n",
            "Epoch 180/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 8.6821e-05 - val_accuracy: 1.0000\n",
            "Epoch 181/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0250 - accuracy: 0.9811 - val_loss: 8.5746e-05 - val_accuracy: 1.0000\n",
            "Epoch 182/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0303 - accuracy: 0.9811 - val_loss: 8.3370e-05 - val_accuracy: 1.0000\n",
            "Epoch 183/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 8.4789e-05 - val_accuracy: 1.0000\n",
            "Epoch 184/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 8.4132e-05 - val_accuracy: 1.0000\n",
            "Epoch 185/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0636 - accuracy: 0.9623 - val_loss: 8.4443e-05 - val_accuracy: 1.0000\n",
            "Epoch 186/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 8.3283e-05 - val_accuracy: 1.0000\n",
            "Epoch 187/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 7.7852e-05 - val_accuracy: 1.0000\n",
            "Epoch 188/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 7.4821e-05 - val_accuracy: 1.0000\n",
            "Epoch 189/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 7.1974e-05 - val_accuracy: 1.0000\n",
            "Epoch 190/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0223 - accuracy: 1.0000 - val_loss: 7.2589e-05 - val_accuracy: 1.0000\n",
            "Epoch 191/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 7.9129e-05 - val_accuracy: 1.0000\n",
            "Epoch 192/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0324 - accuracy: 0.9811 - val_loss: 7.8690e-05 - val_accuracy: 1.0000\n",
            "Epoch 193/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 7.8142e-05 - val_accuracy: 1.0000\n",
            "Epoch 194/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 7.6465e-05 - val_accuracy: 1.0000\n",
            "Epoch 195/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 7.3073e-05 - val_accuracy: 1.0000\n",
            "Epoch 196/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 7.1686e-05 - val_accuracy: 1.0000\n",
            "Epoch 197/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 6.9815e-05 - val_accuracy: 1.0000\n",
            "Epoch 198/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 6.7155e-05 - val_accuracy: 1.0000\n",
            "Epoch 199/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 6.4825e-05 - val_accuracy: 1.0000\n",
            "Epoch 200/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 6.3191e-05 - val_accuracy: 1.0000\n",
            "Epoch 201/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0181 - accuracy: 1.0000 - val_loss: 6.2615e-05 - val_accuracy: 1.0000\n",
            "Epoch 202/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 6.1636e-05 - val_accuracy: 1.0000\n",
            "Epoch 203/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 6.0341e-05 - val_accuracy: 1.0000\n",
            "Epoch 204/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0571 - accuracy: 0.9623 - val_loss: 6.4636e-05 - val_accuracy: 1.0000\n",
            "Epoch 205/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 6.8230e-05 - val_accuracy: 1.0000\n",
            "Epoch 206/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0266 - accuracy: 0.9811 - val_loss: 6.4155e-05 - val_accuracy: 1.0000\n",
            "Epoch 207/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 6.4555e-05 - val_accuracy: 1.0000\n",
            "Epoch 208/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 6.7865e-05 - val_accuracy: 1.0000\n",
            "Epoch 209/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 6.7504e-05 - val_accuracy: 1.0000\n",
            "Epoch 210/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 6.5294e-05 - val_accuracy: 1.0000\n",
            "Epoch 211/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 6.3594e-05 - val_accuracy: 1.0000\n",
            "Epoch 212/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0573 - accuracy: 0.9811 - val_loss: 6.5799e-05 - val_accuracy: 1.0000\n",
            "Epoch 213/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 6.7481e-05 - val_accuracy: 1.0000\n",
            "Epoch 214/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 6.6255e-05 - val_accuracy: 1.0000\n",
            "Epoch 215/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 6.5056e-05 - val_accuracy: 1.0000\n",
            "Epoch 216/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 6.4919e-05 - val_accuracy: 1.0000\n",
            "Epoch 217/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0662 - accuracy: 0.9811 - val_loss: 6.7588e-05 - val_accuracy: 1.0000\n",
            "Epoch 218/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 7.2012e-05 - val_accuracy: 1.0000\n",
            "Epoch 219/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0824 - accuracy: 0.9811 - val_loss: 8.6151e-05 - val_accuracy: 1.0000\n",
            "Epoch 220/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 1.0933e-04 - val_accuracy: 1.0000\n",
            "Epoch 221/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.1350e-04 - val_accuracy: 1.0000\n",
            "Epoch 222/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0244 - accuracy: 1.0000 - val_loss: 1.0844e-04 - val_accuracy: 1.0000\n",
            "Epoch 223/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0377 - accuracy: 0.9811 - val_loss: 1.0586e-04 - val_accuracy: 1.0000\n",
            "Epoch 224/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.0196e-04 - val_accuracy: 1.0000\n",
            "Epoch 225/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 9.1462e-05 - val_accuracy: 1.0000\n",
            "Epoch 226/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 8.3498e-05 - val_accuracy: 1.0000\n",
            "Epoch 227/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 7.7049e-05 - val_accuracy: 1.0000\n",
            "Epoch 228/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 7.4043e-05 - val_accuracy: 1.0000\n",
            "Epoch 229/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 7.1367e-05 - val_accuracy: 1.0000\n",
            "Epoch 230/250\n",
            "11/11 [==============================] - 0s 12ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 6.8945e-05 - val_accuracy: 1.0000\n",
            "Epoch 231/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 6.7614e-05 - val_accuracy: 1.0000\n",
            "Epoch 232/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 6.5770e-05 - val_accuracy: 1.0000\n",
            "Epoch 233/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0450 - accuracy: 0.9623 - val_loss: 6.2933e-05 - val_accuracy: 1.0000\n",
            "Epoch 234/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 6.5294e-05 - val_accuracy: 1.0000\n",
            "Epoch 235/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 6.4687e-05 - val_accuracy: 1.0000\n",
            "Epoch 236/250\n",
            "11/11 [==============================] - 0s 9ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 6.2992e-05 - val_accuracy: 1.0000\n",
            "Epoch 237/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 6.1375e-05 - val_accuracy: 1.0000\n",
            "Epoch 238/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 5.9639e-05 - val_accuracy: 1.0000\n",
            "Epoch 239/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 5.7117e-05 - val_accuracy: 1.0000\n",
            "Epoch 240/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 5.5325e-05 - val_accuracy: 1.0000\n",
            "Epoch 241/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 5.3949e-05 - val_accuracy: 1.0000\n",
            "Epoch 242/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0159 - accuracy: 0.9811 - val_loss: 6.1740e-05 - val_accuracy: 1.0000\n",
            "Epoch 243/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 6.2606e-05 - val_accuracy: 1.0000\n",
            "Epoch 244/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 5.8770e-05 - val_accuracy: 1.0000\n",
            "Epoch 245/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 5.3302e-05 - val_accuracy: 1.0000\n",
            "Epoch 246/250\n",
            "11/11 [==============================] - 0s 11ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 4.9066e-05 - val_accuracy: 1.0000\n",
            "Epoch 247/250\n",
            "11/11 [==============================] - 0s 13ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 4.6795e-05 - val_accuracy: 1.0000\n",
            "Epoch 248/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 4.4719e-05 - val_accuracy: 1.0000\n",
            "Epoch 249/250\n",
            "11/11 [==============================] - 0s 7ms/step - loss: 0.0252 - accuracy: 0.9811 - val_loss: 5.3029e-05 - val_accuracy: 1.0000\n",
            "Epoch 250/250\n",
            "11/11 [==============================] - 0s 8ms/step - loss: 0.0245 - accuracy: 0.9811 - val_loss: 5.9472e-05 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(history.history).plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Mq8YGwSS7KFk",
        "outputId": "66240039-98e5-4eda-a880-d9b658fecc7a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f0998b89610>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('chatbot_model.h5', history)\n",
        "print(\"model Saved\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dFkj00W7TLD",
        "outputId": "e8fcdd64-a6ee-4f6e-fe86-c2071610af3e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model Saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "yiqcLJ6x7YWD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}